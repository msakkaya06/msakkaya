{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Karakter_Seviyesi_Dil_Modeli_Dinazor_Adası.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"inm1nzWfr6-3","colab_type":"text"},"cell_type":"markdown","source":["# Karakter Seviyesi Dil Modeli - Dinazor Adası\n","\n","\n","\n","---\n","\n","\n","[<img align=\"right\" width=\"100\" height=\"100\" src=\"http://www.i2symbol.com/images/symbols/style-letters/circled_latin_capital_letter_a_u24B6_icon_128x128.png\">](https://www.ayyucekizrak.com/)"]},{"metadata":{"id":"bE3nT-_D4dZp","colab_type":"text"},"cell_type":"markdown","source":["\n","Daha önce toplanmış olan dinazor isimleri dinos.txt dosyasında tutulmaktadır. Bu veriler kullanılarak yeni dinazor isimleri üretmek için karakter seviyesinde dil modeli oluşturulacaktır. Algoritmanız veri kümenizdeki bazı örüntüleri öğrenerek rastgele yeni isimler üretecek.    \n","\n","Bu uygulama ile şunları öğreneceksiniz.\n","\n","- RNN ile işlenen metin verileri nasıl saklanır\n","- Karakter seviyesinde metin üreten RNN nasıl oluşturulur\n","- Gradyan kırpma neden önemlidir\n","\n","İlk olarak kendi hazırladığımız `utils` dosyasından bazı fonksiyonları ve `numpy` kütüphanesini dahil ederek başlıyoruz. "]},{"metadata":{"id":"JZBTYRXt4dZr","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from utils import *\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mMGGEDJj4dZu","colab_type":"text"},"cell_type":"markdown","source":["## 1 - Problem Tanımı\n","\n","### 1.1 - Veri Kümesi ve Ön İşlemler\n","\n","Dinazor isimlerinden oluşan veri kümesini okuyalım, a'dan z'ye karakterlerden oluşan listeler oluşturalım, veri kümesi ve oluşturduğumuz sözlüğün boyutlarını hesaplayalım."]},{"metadata":{"id":"ylBHAm-n4dZu","colab_type":"code","outputId":"9f57761f-4885-4d3a-8126-c313fcf94b56","colab":{}},"cell_type":"code","source":["data = open('dinos.txt', 'r').read()\n","data= data.lower()\n","chars = list(set(data))\n","data_size, vocab_size = len(data), len(chars)\n","print('Veriniz toplam %d karakterden ve %d tekil karakterden oluşmaktadır.' % (data_size, vocab_size))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Veriniz toplam 19911 karakterden ve 27 tekil karakterden oluşmaktadır.\n"],"name":"stdout"}]},{"metadata":{"id":"bgPL_PCJ4dZy","colab_type":"text"},"cell_type":"markdown","source":["Oluşturduğumuz sözlük 26 karakterden (a-z) ve 1 adet yeni satır karakterinden (\\n) oluşmaktadır. Aşağıdaki hücrede her bir karakterin 1-26 arasında bir sayı karşılığının olduğu Python sözlüğü (dictionary) oluşturuyoruz. Aynı şekilde sayıdan karaktere dönüşümü sağlamak için ikinci bir sözlük oluşturuyoruz."]},{"metadata":{"id":"jWn9GK6r4dZz","colab_type":"code","outputId":"27ec8fa5-2709-48ec-e9ef-8ed0e25d927e","colab":{}},"cell_type":"code","source":["char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n","ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n","print(ix_to_char)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"],"name":"stdout"}]},{"metadata":{"id":"Y5EMpzcr4dZ3","colab_type":"text"},"cell_type":"markdown","source":["### 1.2 - Modele Genel Bir Bakış\n","\n","Modelinizde şunlar olacak: \n","\n","- Parametreleri ilklendir \n","- Optimizasyon döngüsü\n","    - Yitim fonksiyonunu hesaplamak için ileri yönlü hesaplama\n","    - Gradyan hesabı için geriye yayılım\n","    - Gradyanlar patlamasını önlemek için gradyanları kırp\n","    - Gradyanları kullanarak parametreleri güncelle\n","- Öğrenilen parametreleri döndür \n","    \n","Her bir zaman adımında, RNN önceki karakterlere bağlı olarak bir sonraki karakterin ne olduğunu tahmin etmeye çalışır. Veri kümesi; $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, ..., x^{\\langle T_x \\rangle})$ eğitim kümesinde bulunan karakter listelerinden ve $Y = (y^{\\langle 1 \\rangle}, y^{\\langle 2 \\rangle}, ..., y^{\\langle T_x \\rangle})$ her bir $t$ anındaki çıkış değerlerinden oluşmaktadır. Tahmin edebileceğiniz gibi $y^{\\langle t \\rangle} = x^{\\langle t+1 \\rangle}$ eşitliği bulunmaktadır. "]},{"metadata":{"id":"wQ5Uj_o44dZ3","colab_type":"text"},"cell_type":"markdown","source":["## 2 - Modele ait Blokları Oluşturma\n","\n","Bu bölümde, modele ait çok önemli iki parçayı oluşturacaksınız: \n","\n","- Gradyan kırpma: Gradyan patlamasını önlemek için\n","- Örnekleme: karakter oluşturmada kullanılan yöntem"]},{"metadata":{"id":"B6XuPDfG4dZ3","colab_type":"text"},"cell_type":"markdown","source":["### 2.1 - Gradyan Kırpma\n","\n","Bu bölümde optimizasyon döngüsü içerisinde `clip` fonksiyonunu tanımlayacağız. Genel döngünün maliyet hesabının yapıldığı ileri yönlü hesaplama ve parametre güncellemelerinin yapıldığı geriye yayılım adımlarından oluştuduğunu hatırlayın. Gradyan patlamasını yani gradyanların büyük değerler almasını önlemek için parametre güncelleme işleminden önce gradyan kırpma işlemi gerçekleştirilmektedir.\n","\n","Aşağıda gradyanları giriş olarak alan ve ihtiyaç var ise çıktı olarak kırpılmış versiyonlarını döndüren `clip` fonksiyonunu tanımlayacağız. Gradyan kırpmanın birçok farklı yöntemi bulunmaktadır. Biz burada gradyan vektörünün her bir elemanını [-N, N] aralığına indirgeyeceğiz. Bunu gerçekleştirmek için `maxValue` isimli bir değişken tanımlayıp değerini örneğin 10 olarak belirleyeceğiz. Gradyan kırpma işlemind değerler 10'dan büyük ise yeni değer 10 olarak, -10'dan küçük ise yeni değer -10 olarak ayarlanacaktır. Yani gradyan değerleri hiç bir şekilde gradyanların mutlak değeri `maxValue` değerinden küçük olamaz."]},{"metadata":{"id":"Jq2bd_9A4dZ5","colab_type":"code","colab":{}},"cell_type":"code","source":["def clip(gradients, maxValue):\n","    '''\n","    Gradyan değerlerini maksimum ve minimum değerleri arasında tutar.\n","    \n","    Giriş:\n","    gradients -- \"dWaa\", \"dWax\", \"dWya\", \"db\", \"dby\" gradyanlarını içeren gradyan vektörü\n","    maxValue -- gradyanların kırpılacağı değer \n","    \n","    Çıkış: \n","    gradients -- kırpılmış gradyan\n","    '''\n","    \n","    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n","   \n","    # gradyanları kırpalım [dWax, dWaa, dWya, db, dby]. \n","    for gradient in [dWax, dWaa, dWya, db, dby]:\n","        gradients = np.clip(gradient, -10, maxValue, out=gradient)\n","    \n","    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n","    \n","    return gradients"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OfXNgpVU4dZ6","colab_type":"code","outputId":"e60a3066-51d2-484b-92ce-e9b9c67115bb","colab":{}},"cell_type":"code","source":["np.random.seed(3)\n","dWax = np.random.randn(5,3)*10\n","dWaa = np.random.randn(5,5)*10\n","dWya = np.random.randn(2,5)*10\n","db = np.random.randn(5,1)*10\n","dby = np.random.randn(2,1)*10\n","gradients = {\"dWax\": dWax, \"dWaa\": dWaa, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n","gradients = clip(gradients, 10)\n","print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n","print(\"gradients[\\\"dWax\\\"][3][1] =\", gradients[\"dWax\"][3][1])\n","print(\"gradients[\\\"dWya\\\"][1][2] =\", gradients[\"dWya\"][1][2])\n","print(\"gradients[\\\"db\\\"][4] =\", gradients[\"db\"][4])\n","print(\"gradients[\\\"dby\\\"][1] =\", gradients[\"dby\"][1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gradients[\"dWaa\"][1][2] = 10.0\n","gradients[\"dWax\"][3][1] = -10.0\n","gradients[\"dWya\"][1][2] = 0.2971381536101662\n","gradients[\"db\"][4] = [10.]\n","gradients[\"dby\"][1] = [8.45833407]\n"],"name":"stdout"}]},{"metadata":{"id":"TXwrnVad4dZ-","colab_type":"text"},"cell_type":"markdown","source":["### 2.2 - Örnekleme\n","\n","Modelinizin eğitildiğini varsayın. Yeni metinler oluşturmak istiyorsunuz.\n","\n","`sample` ismindeki fonksiyonu kullanarak karakterleri 4 adımda örnekleyeceğiz:\n","\n","- **Adım 1**: İlk önce sıfır vektörünü ağımıza giriş olarak verelim. $x^{\\langle 1 \\rangle} = \\vec{0}$ Böylecek herhangi bir metin oluşturmadan önce varsayılan değerimiz bu giriş vektörü olacak. Ayrıca aktivasyon değerlerini de şu şekilde tanımlayalım: $a^{\\langle 0 \\rangle} = \\vec{0}$\n","\n","- **Adım 2**: $a^{\\langle 1 \\rangle}$ ve $\\hat{y}^{\\langle 1 \\rangle}$ vektörlerini elde etmek için bir adım ileri yönlü hesaplama yapalım. Kullandığımız bazı denklemler:\n","\n","$$ a^{\\langle t+1 \\rangle} = \\tanh(W_{ax}  x^{\\langle t \\rangle } + W_{aa} a^{\\langle t \\rangle } + b)\\tag{1}$$\n","\n","$$ z^{\\langle t + 1 \\rangle } = W_{ya}  a^{\\langle t + 1 \\rangle } + b_y \\tag{2}$$\n","\n","$$ \\hat{y}^{\\langle t+1 \\rangle } = softmax(z^{\\langle t + 1 \\rangle })\\tag{3}$$\n","\n","$\\hat{y}^{\\langle t+1 \\rangle }$'in (softmax) olasılık vektörü olduğunu, değerlerinin 0-1 arasında olduğunun ve toplam değerin 1 olduğunu unutmayın. $\\hat{y}^{\\langle t+1 \\rangle}_i$ değeri \"i.\" bir sonraki karakterin olasığının göstermektedir. \n","\n","- **Adım 3**: Bu adımda örnekleme gerçekleştirilmektedir. $\\hat{y}^{\\langle t+1 \\rangle }$ değerinin $\\hat{y}^{\\langle t+1 \\rangle }_i = 0.16$ olması durumunda \"i.\" karakteri %16 olasılıkla seçeceğiniz anlamına gelir.\n","\n","- **Adım 4**: Bu adımda $x^{\\langle t \\rangle }$ değeri $x^{\\langle t + 1 \\rangle }$ değeriyle değiştirilmektedir."]},{"metadata":{"id":"7Ljqoy8O4dZ_","colab_type":"code","colab":{}},"cell_type":"code","source":["def sample(parameters, char_to_ix, seed):\n","    \"\"\"\n","    RNN olasılık çıkış değerlerine göre karakter dizisi örneklenir \n","\n","    Giriş:\n","    parameters -- Waa, Wax, Wya, by, ve b değerlerini içeren Python dictionary \n","    char_to_ix -- Her bir karakteri indeks değerine haritalayan Python dictionary\n","    seed -- tekrarlanabilirlik için\n","\n","    Çıkış:\n","    indices -- örneklenen karakterlerin uzunluğunu tutan liste\n","    \"\"\"\n","    \n","    # \"parameters\" sözlüğünden parametreleri alalım\n","    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n","    vocab_size = by.shape[0]\n","    n_a = Waa.shape[1]\n","    \n","    # Adım 1: ilk karakter için x one-hot vektörünü oluşturalım\n","    x = np.zeros((vocab_size,1))\n","    # Adım 1': \"a_prev\" değerlerini sıfır olarak ilklendirelim \n","    a_prev = np.zeros((n_a,1))\n","    \n","    # boş bir indis listesi oluşturalım. \n","    indices = []\n","    \n","    # Idx yeni satır karakteri tespit etmek için. -1 olarak ilklendirelim\n","    idx = -1 \n","    \n","    # t zaman adımlarında döngüyü gerçekleştirelim. \n","    # her bir zaman adımında olasılık dağılımına göre örneklenen karakterin indisi \"indices\" listesine eklenir. \n","    # 50 karaktere ulaşırsa durduracağız.\n","    # iyi eğitilmiş bir modelde 50 karakter çok fazla.\n","\n","    counter = 0\n","    newline_character = char_to_ix['\\n']\n","    \n","    while (idx != newline_character and counter != 50):\n","        \n","        # Adım 2: (1), (2) ve (3) denklemleri kullanılarak ileri yönlü hesaplama yapalım\n","        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev)+ b) #b[:,0]\n","        z = np.dot(Wya,a) + by \n","        y = softmax(z)\n","        \n","        np.random.seed(counter+seed) \n","        \n","        # Adım 3: Olasılık dağılımından karakterlerin indekslerinin örneklenmesi\n","        idx = np.random.choice(range(vocab_size), p = y.ravel())\n","        \n","        # indeks değerini \"indices\"e ekleyelim\n","        indices.append(idx)\n","        \n","        # Adım 4: Giriş karakteri ile örneklenen indeks değerine karşılık gelen karakteri değiştirilir\n","        x =  np.zeros((vocab_size,1))\n","        x[idx] = 1\n","        \n","        # \"a_prev\" değerini \"a\" ile güncelleyelim\n","        a_prev = a\n","        \n","        seed += 1\n","        counter +=1\n","        \n","    if (counter == 50):\n","        indices.append(char_to_ix['\\n'])\n","    \n","    return indices"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Apny1EqK4daC","colab_type":"code","outputId":"04557f8a-179e-47aa-bba3-ccbee17f1378","colab":{}},"cell_type":"code","source":["np.random.seed(2)\n","_, n_a = 20, 100\n","Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)\n","b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)\n","parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"b\": b, \"by\": by}\n","\n","indices = sample(parameters, char_to_ix, 0)\n","print(\"Örnekleme:\")\n","print(\"örneklenen indis listesi:\", indices)\n","print(\"örneklenen karakterler:\", [ix_to_char[i] for i in indices])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Örnekleme:\n","örneklenen indis listesi: [12, 17, 24, 14, 13, 9, 10, 22, 24, 6, 13, 11, 12, 6, 21, 15, 21, 14, 3, 2, 1, 21, 18, 24, 7, 25, 6, 25, 18, 10, 16, 2, 3, 8, 15, 12, 11, 7, 1, 12, 10, 2, 7, 7, 11, 17, 24, 12, 19, 1, 0]\n","örneklenen karakterler: ['l', 'q', 'x', 'n', 'm', 'i', 'j', 'v', 'x', 'f', 'm', 'k', 'l', 'f', 'u', 'o', 'u', 'n', 'c', 'b', 'a', 'u', 'r', 'x', 'g', 'y', 'f', 'y', 'r', 'j', 'p', 'b', 'c', 'h', 'o', 'l', 'k', 'g', 'a', 'l', 'j', 'b', 'g', 'g', 'k', 'q', 'x', 'l', 's', 'a', '\\n']\n"],"name":"stdout"}]},{"metadata":{"id":"OPHlMtcH4daE","colab_type":"text"},"cell_type":"markdown","source":["## 3 - Dil Modelini Oluşturma\n","\n","Yeni metin oluşturabilmek için karakter seviyesi dil modelini oluşturalım.\n","\n","\n","### 3.1 - Gradyan Düşümü \n","\n","Bu bölümde stokastik gradyan düşümü algoritmasını bir adım gerçekleyen bir fonksiyonu tanımlayacağız. RNN için bir adım optimizasyon döngüsü şu şekilde:\n","\n","    - Yitim fonksiyonunu hesaplamak için ileri yönlü hesaplama\n","    - Gradyan hesabı için geriye yayılım\n","    - Gradyanlar patlamasını önlemek için gradyanları kırp\n","    - Gradyanları kullanarak parametreleri güncelle\n","\n","**Örneğin**: Optimizasyon işlemlerinin uygulanması (bir adım Gradyan İniş Algoritması). \n","\n","\n","\n","```python\n","def rnn_forward(X, Y, a_prev, parameters):\n","    \"\"\" İleri yyayılım performansı (RNN için) cross-entropyler hesaplanır ve 'cache' de tutulur.\"\"\"\n","    ....\n","    return loss, cache\n","    \n","def rnn_backward(X, Y, parameters, cache):\n","    \"\"\"Parametrelere göre kayıp gradyanlarını hesaplamak için zamanla geriye doğru yayılımı gerçekleştirir. Ayrıca tüm gizli durumları da döndürür.\"\"\"\n","    ...\n","    return gradients, a\n","\n","def update_parameters(parameters, gradients, learning_rate):\n","    \"\"\"Gradient Descent Güncelleme Kuralını kullanarak güncellemeler parametreleri.\"\"\"\n","    ...\n","    return parameters\n","```"]},{"metadata":{"id":"WqxH2V0j4daF","colab_type":"code","colab":{}},"cell_type":"code","source":["def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n","    \"\"\"\n","    Modeli eğitmek için bir adım optimizasyon uygulayalım\n","    \n","    Girdiler:\n","    X -- tamsayı listesi, her bir sayı sözlükte bir karakteri belirtir\n","    Y -- tamsayı listesi, X ile aynı fakat sola doğru 1 indeks kaydırılmış hali\n","    a_prev -- geçmiş saklı durumlar\n","    parameters -- Python sözlüğü:\n","                        Wax -- Ağırlık matrisi ile giriş çaprımı, (n_a, n_x) boyutlu Numpy dizisi\n","                        Waa -- Ağırlık matiris ile saklı durum çarpımı, (n_a, n_a) boyutlu Numpy dizisi\n","                        Wya -- Saklı durumdan çıkışa ağırlık matrisi, (n_y, n_a) boyutlu Numpy dizisi\n","                        b --  Bias, (n_a, 1) boyutlu Numpy dizisi\n","                        by -- Saklı durumdan çıkışa Bias, (n_y, 1) boyutlu Numpy dizisi   \n","    \n","    learning_rate -- öğrenme oranı\n","    \n","    Çıktılar:\n","    loss -- yitim fonksiyonu değeri (cross-entropy)\n","    gradients -- python dictionary:\n","                        dWax -- Girişten gizli katmana ağırlık gradyanları, boyut: (n_a, n_x)\n","                        dWaa -- Gizliden gizli katmana ağırlık gradyanları, boyut: (n_a, n_a)\n","                        dWya -- Gizliden çıkışa ağırlık gradyanı, boyut: (n_y, n_a)\n","                        db -- Bias vektörünün gradyanı, boyut: (n_a, 1)\n","                        dby -- Çıkış bias vektörünün gradyanı, boyut: (n_y, 1)\n","    a[len(X)-1] -- en son saklı durum, boyut: (n_a, 1)\n","    \"\"\"\n","        \n","    # zamanda ileri yayılım\n","    # ileri yönlü hesaplama yapılarak cross-entropy yitimi hesaplanır.\n","    # yitim değerinin yanında cache değerleri de döndürülür\n","    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n","    \n","    # zamanda geri yayılım\n","    # gradyan hesaplaması yapılır.\n","    # saklı durumlar da döndürülür.    \n","    gradients, a = rnn_backward(X, Y, parameters, cache)\n","    \n","    # Gradyanları -5 (minimum) ve 5 (maksimum) arasında kırpalım\n","    gradients = clip(gradients, 5)\n","    \n","    # Parametre güncellemesi\n","    parameters = update_parameters(parameters, gradients, learning_rate)\n","        \n","    return loss, gradients, a[len(X)-1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NlqJmlwB4daH","colab_type":"code","outputId":"8ab6d212-7c77-4799-c342-a85b6def1c43","colab":{}},"cell_type":"code","source":["np.random.seed(1)\n","vocab_size, n_a = 27, 100\n","a_prev = np.random.randn(n_a, 1)\n","Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)\n","b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)\n","parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"b\": b, \"by\": by}\n","X = [12,3,5,11,22,3]\n","Y = [4,14,11,22,25, 26]\n","\n","loss, gradients, a_last = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)\n","print(\"Loss =\", loss)\n","print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n","print(\"np.argmax(gradients[\\\"dWax\\\"]) =\", np.argmax(gradients[\"dWax\"]))\n","print(\"gradients[\\\"dWya\\\"][1][2] =\", gradients[\"dWya\"][1][2])\n","print(\"gradients[\\\"db\\\"][4] =\", gradients[\"db\"][4])\n","print(\"gradients[\\\"dby\\\"][1] =\", gradients[\"dby\"][1])\n","print(\"a_last[4] =\", a_last[4])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loss = 126.50397572165339\n","gradients[\"dWaa\"][1][2] = 0.19470931534726663\n","np.argmax(gradients[\"dWax\"]) = 93\n","gradients[\"dWya\"][1][2] = -0.007773876032004546\n","gradients[\"db\"][4] = [-0.06809825]\n","gradients[\"dby\"][1] = [0.01538192]\n","a_last[4] = [-1.]\n"],"name":"stdout"}]},{"metadata":{"id":"vzlJ3fvj4daL","colab_type":"text"},"cell_type":"markdown","source":["### 3.2 - Modelin Eğitimi "]},{"metadata":{"id":"e5n8ggPo4daM","colab_type":"text"},"cell_type":"markdown","source":["Dinazor isimlerinden oluşan veri kümesinde her bir satır bir eğitim örneğidir. Her 100 stokastastik gradyan düşümü adımında, rastgele 10 örnek üretilir. Stokastik gradyan düşümünün örnekleri rastgele ziyaret etmek için veri kümesi karıştırılır."]},{"metadata":{"id":"Hb8CPenr4daM","colab_type":"code","colab":{}},"cell_type":"code","source":["def model(data, ix_to_char, char_to_ix, num_iterations = 35000, n_a = 50, dino_names = 7, vocab_size = 27):\n","    \"\"\"\n","    Modeli eğitir ve dinazor isimleri üretir\n","    \n","    Girdiler:\n","    data -- metin corpus\n","    ix_to_char -- indeksten karaktere haritalama\n","    char_to_ix -- karakterden indekse haritalama\n","    num_iterations -- modelin eğitimi için iterasyon sayısı\n","    n_a -- RNN hücresindeki birim sayısı \n","    dino_names -- her bir iterasyonda örneklenecek dinazor ismi sayısı \n","    vocab_size -- metinde bulunan tekil karakter sayısı \n","    \n","    Çıktı:\n","    parameters -- öğrenilen parametreler\n","    \"\"\"\n","    \n","    # vocab_size'dan n_x ve n_y değerlerini alalım \n","    n_x, n_y = vocab_size, vocab_size\n","    \n","    # parametreleri ilklendirelim\n","    parameters = initialize_parameters(n_a, n_x, n_y)\n","    \n","    # yitim fonksiyonunu ilklendirelim\n","    loss = get_initial_loss(vocab_size, dino_names)\n","    \n","    # eğitim örneklerini kullanarak dinazor isimlerini listeleyelim\n","    with open(\"dinos.txt\") as f:\n","        examples = f.readlines()\n","    examples = [x.lower().strip() for x in examples]\n","    \n","    # Dinazor isimlerini karıştıralım\n","    np.random.seed(0)\n","    np.random.shuffle(examples)\n","    \n","    # LSTM gizli durumunu (hidden state) ilklendirelim\n","    a_prev = np.zeros((n_a, 1))\n","    \n","    # Optimizasyon döngüsü\n","    for j in range(num_iterations):\n","            \n","        index = j % len(examples)\n","        X = [None] + [char_to_ix[ch] for ch in examples[index]] \n","        Y = X[1:] + [char_to_ix[\"\\n\"]]\n","        \n","        # Optimizasyon döngüsü: ileri hesaplama -> geriye yayılım -> kırpma -> parametre güncelle\n","        # Öğrenme oranını 0.01 olarak seçelim\n","        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)\n","                \n","        # latency trick kullanarak yitimini düzleştirelim (smooth). Eğitimi hızlandırır.\n","        loss = smooth(loss, curr_loss)\n","\n","        # Her 2000 iterasyonda sample() fonksiyonu ile \"n\" karakter oluşturalım\n","        # modelin iyi eğitildiği kontrol edilir\n","        if j % 2000 == 0:\n","            \n","            print('İterasyon: %d, Yitim: %f' % (j, loss) + '\\n')\n","            \n","            # Ekrana yazdırılacak dinazor ismi sayısı\n","            seed = 0\n","            for name in range(dino_names):\n","                \n","                # Örneklenen indisler \n","                sampled_indices = sample(parameters, char_to_ix, seed)\n","                print_sample(sampled_indices, ix_to_char)\n","                \n","                seed += 1\n","      \n","            print('\\n')\n","        \n","    return parameters"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xpToxwy94daP","colab_type":"text"},"cell_type":"markdown","source":["Üstteki hücreyi çalıştırdığınızda modelinizin ilk önce rastgele karakterler daha sonra ise makul isimler ürettiğini gözlemleyeceksiniz."]},{"metadata":{"id":"ROt8MBvw4daQ","colab_type":"code","outputId":"1908361a-e2c2-458f-a9a4-9ca103b23870","colab":{}},"cell_type":"code","source":["parameters = model(data, ix_to_char, char_to_ix)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["İterasyon: 0, Yitim: 23.087336\n","\n","Nkzxwtdmfqoeyhsqwasjkjvu\n","Knfb\n","Kzxwtdmfqoeyhsqwasjkjvu\n","Nfb\n","Zxwtdmfqoeyhsqwasjkjvu\n","Fb\n","Xwtdmfqoeyhsqwasjkjvu\n","\n","\n","İterasyon: 2000, Yitim: 27.967193\n","\n","Livtosaurus\n","Hlca\n","Hwtosaurus\n","Lacahosanaus\n","Xusalncoolurus\n","A\n","Tosaurus\n","\n","\n","İterasyon: 4000, Yitim: 25.730191\n","\n","Livosaurus\n","Hmba\n","Iusosaurus\n","Ledalosaurus\n","Xusmaneroptosaurus\n","Baagosaurus\n","Torapgosaurus\n","\n","\n","İterasyon: 6000, Yitim: 24.635574\n","\n","Onyusalonosaurus\n","Lleeacosaurus\n","Lyusqcheromus\n","Olaberriceptosaurus\n","Xusteolosaurus\n","Edalosaurus\n","Trogonosaurus\n","\n","\n","İterasyon: 8000, Yitim: 24.221203\n","\n","Niushuhelnomus\n","Jia\n","Kutrodhchiaterauaurus\n","Nca\n","Xutokellolus\n","Caagropaboter\n","Trodhcholus\n","\n","\n","İterasyon: 10000, Yitim: 23.775948\n","\n","Niwrosaurus\n","Kiacalosaurus\n","Lustoinatopteriuaneonsharriyilanbesaurus\n","Necairona\n","Xtrocheorax\n","Caadosaurus\n","Trocheorax\n","\n","\n","İterasyon: 12000, Yitim: 23.310353\n","\n","Onyusaorashevasaurus\n","Liacalosaurus\n","Lustrapdoraxaurochlanosaurus\n","Olaalosaurus\n","Xussanchudyanitasaurus\n","Daakrolabnsaurosqracxalosaurus\n","Strapanlaverataramnptaronylealaluakachiachatolonha\n","\n","\n","İterasyon: 14000, Yitim: 23.323893\n","\n","Meytosaurus\n","Imeca\n","Iustoimanonuroruchus\n","Macaersia\n","Xusnanespeuroptaraptor\n","Caaertia\n","Stochenonumusianisaurastov\n","\n","\n","İterasyon: 16000, Yitim: 23.126425\n","\n","Liusoraps\n","Hiceacosaurus\n","Iuskoendonavenosaurus\n","Lecagppia\n","Wuslanchods\n","Caaeron\n","Stodon\n","\n","\n","İterasyon: 18000, Yitim: 22.717464\n","\n","Optosaurus\n","Jidcalosaurus\n","Kyxsolophodys\n","Omabespegasoosaurus\n","Xusonkisaurus\n","Dabesricerosdenotliavenosaurus\n","Strgodosaurus\n","\n","\n","İterasyon: 20000, Yitim: 22.913655\n","\n","Leytosaurus\n","Indaberrhagosaurus\n","Iustrerasaurus\n","Lebaisig\n","Wstohiblontfros\n","Caagosaurus\n","Stokicor\n","\n","\n","İterasyon: 22000, Yitim: 22.841440\n","\n","Liustreratopteryx\n","Godacerope\n","Hustreratopteryx\n","Lecakus\n","Wursaurus\n","Dbahusaurus\n","Trrangosaurus\n","\n","\n","İterasyon: 24000, Yitim: 22.501143\n","\n","Knwpronia\n","Frabalosaurus\n","Gusoraphus\n","Keaalosaurus\n","Wurognasaurus\n","Baahosaurus\n","Stolonosaurus\n","\n","\n","İterasyon: 26000, Yitim: 22.777890\n","\n","Liuspognisaurus\n","Hola\n","Hytrodonkolumopteronestanuasaurus\n","Lecainodhansaurus\n","Wusodon\n","Cebasia\n","Trodonophus\n","\n","\n","İterasyon: 28000, Yitim: 22.678113\n","\n","Liuspteratops\n","Inda\n","Ivrosaurus\n","Lgabers\n","Wussangs\n","Deachyidan\n","Trraphus\n","\n","\n","İterasyon: 30000, Yitim: 22.562026\n","\n","Kouspoldonjaudontasaurus\n","Eracalptodanpescgotocax\n","Gustripaniaudrosaurus\n","Lacalotel\n","Wusolomosaurus\n","Agacosaurus\n","Trochion\n","\n","\n","İterasyon: 32000, Yitim: 22.293545\n","\n","Levotoimanpatosaurus\n","Eracaltodeerus\n","Hyusolenotourus\n","Lacalosaurus\n","Wutolncoraxnosaurus\n","Dabasona\n","Usteodon\n","\n","\n","İterasyon: 34000, Yitim: 22.512174\n","\n","Leyuskaneosaurus\n","Hegaamosaurus\n","Hytspeneus\n","Lacalosaurus\n","Wtpsaurus\n","Caahosaurus\n","Usqangosaurus\n","\n","\n"],"name":"stdout"}]},{"metadata":{"id":"lqfoBg3q4daS","colab_type":"text"},"cell_type":"markdown","source":["## Sonuç\n","\n","Görüldüğü üzere algoritmanız eğitimin sonlarına doğru daha iyi dinazor isimleri üretmeyi başardı. <img align=\"right\" width=\"300\" height=\"150\" src=\"https://www.yayomg.com/wp-content/uploads/2016/02/yayomg-good-dinosaur-life-lessons-7.gif\">\n","\n","İlk başlarda rastgele karakter dizileri oluşturulurken sonlara doğru daha makul isimler üretilmeye başlandı. \n","\n","\n","**`maconucon`**, **`marloralus`** and **`macingsersaurus`** gibi isimler üretilmiştir.\n","\n","\n","Geliştirdiğimiz model dinazor isimlerinin **`saurus`**, **`don`**, **`aura`**, **`tor`** vb. ile bittiğini öğrenmiştir.\n","\n"]}]}