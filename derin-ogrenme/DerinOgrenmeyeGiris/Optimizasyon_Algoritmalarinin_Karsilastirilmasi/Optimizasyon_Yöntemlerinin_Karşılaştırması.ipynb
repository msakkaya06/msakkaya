{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Optimizasyon_Yöntemlerinin_Karşılaştırması.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oA7pWHsNPLdl"},"source":["# Derin Öğrenme İçin Optimizasyon Yöntemlerinin Karşılaştırılması\n","\n","---\n","Hayatımız optimizasyonla ilgili aslında evden çıkıyorsunuz işe, okula, arkadaşlarınızla buluşmaya ya da her nereyse gitmek için en kısa, en konforlu, en manzaralı, en ucuz gibi çeşitli yol alternatifleriniz var ve siz hem konforlu hem hızlı hem de manzaralı olsun istiyorsunuz 😎 Buna göre mümkün olan en uygun yolu seçiyorsunuz ama biraz daha fazla para ödemiş oluyorsunuz. 💸  İşte bu yaptığınız iş doğal bir **ödünleşim yani optimizasyon**. Sürekli zaman-maliyet-başarım gibi kriterleri birbirlerine göre kıyaslayıp orta noktada buluşmaya çalışıyorsunuz. Bir konuyu arkadaşınızla tartışırken bile bunu yapıyorsunuz hiç farketmediniz mi? \n","\n","🎯 **İşte özetle optimizasyon bu!** \n","\n","![Optimizasyon](https://gifimage.net/wp-content/uploads/2017/01/Happy-Dance-GIF-Image-for-Whatsapp-and-Facebook-7.gif)\n","\n","\n","\n","---\n","Bir makine öğrenmesi/derin öğrenme/yapay sinir ağı modeli tasarladığımızda da amacımız hatayı minimize etmektir. Bunun için daha hızlı fakat lokal minimumlara takılma ihtimali olan bir algoritma, ya da daha yavaş ama daha güvenli bir algoritma gibi bir çok seçeneğimiz var, özetle matematiğine de değineceğim. Ancak optimizasyon algoritmasını seçerken de küçük bir optimizasyon yapmamız gerekir. Ne istiyoruz? Ne kadar işlem yapma kapasitemiz var? Eğitimin ne kadar sürmesini istiyoruz? Hatayı ne kadar minimuma indirmemiz bizim işimizi görür? Buna uygun olacak türden bir algoritmayı tercih etmemiz gerekir. \n","\n","---\n","\n","Bunun için MNIST veri seti için basit bir Evrişimli Sİnir ağı modeli tercih edilmiştir. \n","\n","\n","*   Stokastik Bayır/Gradyan İniş (Stochastic Gradient Descent-SDG)\n","*   RMSprop Optimizasyonu\n","*   Adagrad Optimizasyonu\n","*   Adadelta Optimizasyonu\n","*   Adam Optimizasyonu\n","\n","\n","Ağırlıklar ve bias değerleri gibi model parametrelerini güncelleyerek Yapay Sinir Ağı modeliniz için hangi optimizasyon algoritmasını kullanacağınızı hiç merak ettiniz mi? Gradyan İniş veya Stokastik Gradyan İniş veya Adam hangisini ne zaman tercih etmeliyiz?\n","\n","---\n","### BASİTÇE DERİN ÖĞRENME ANATOMİSİ\n","\n","**DerinÖğrenme(x)= Model(x) + MaliyetFonksiyonu(Model(x)) + GirişVeriSeti (x) + Optimizasyon(MaliyetFonksiyonu(x))**\n","\n","Derin öğrenme modeli olurştururken kafayı yememize sebep olan bir sürü parametre ve hiperparametre ayarlamamız gerekir. Amacımızı temel olarak iki ana gruba ayırabiliriz:\n","* Maliyet fonksiyonunu azaltmak\n","* Genel hatayı minimize etmek\n","\n","Bunun için **optimizasyon** ve **regularizasyon/düzgünleştirme** denen iki önemli hadise mevcuttur. Bu çalışma dosyasında optimizasyon konusuna odaklanıyoruz. Derin öğrenme diyince optimizasyon fonksiyonu olarak **Stokastik Gradyan/Bayır İniş algoritması** ilk akla gelen ve en çok kullanılan maliyet fonksiyonunu minimize etme yöntemidir. Neden böyle olduğunu çalışmanın sonunda daha net anlayacaksınız!\n","\n","### Gradyan/Bayır İniş Nedir? \n","Akıllı Sistemleri nasıl eğittiğimize ve optimize ettiğimize dair en önemli teknik ve temeldir. \n","\n","---\n","\n","İlk olarak, gradyan iniş ve ilişkili adımların, değişkenlerinin ayrıntılarına girmeden önce lojistik regresyonda nasıl çalıştığını görelim. Basitlik adına, lojistik regresyon modelinin sadece iki parametresi olduğunu varsayalım: ağırlık **w** ve biası **b**.\n","\n","1. Ağırlık w ve önyargı b'yi herhangi bir rasgele sayıya sıfırlayın.\n","2. α öğrenme oranı için bir değer seçin. Öğrenme hızı, adımların her bir yinelemede ne kadar büyük olacağını belirler.\n","\n","> * α çok küçükse, yakınsaması ve hesaplama açısından maliyetli hale ve uzun zaman alacaktır.\n","\n","> * α büyükse, minimumda ulaşma başarısız olabilir.\n","Bu nedenle, maliyet fonksiyonunu α'nın farklı değerlerine karşı çizin ve yakınsak olan ilk değerden hemen önceki α'nın değerini seçin, böylece yakınsak olan çok hızlı bir öğrenme algoritmasına sahip olacaktık.\n","> * En yaygın kullanılan öğrenme oranları: 0,001, 0,003, 0,01, 0,03, 0,1, 0,3'tür. \n","Tabi öğrenme oranına göre gradyan iniş algoritmasının karşılaştırılması yapılabilir. Gradyan iniş ile yitim fonksiyonunu minimize ederken öğrenme oranını değiştirirsek durum yine değişecektir. Bu da ayrı bir çalışmanın konusu olsun 😃 \n","\n","![Loss-Epoch](https://i.hizliresim.com/qdnnaQ.jpg)\n","\n","3. Verilerin çok farklı ölçeklerde olup olmadığını ölçeklendirdiğinizden (normalize ettiğinizden) emin olun. Verileri ölçeklendirmezsek, seviye eğrileri daha dar ve daha uzun olur, bu da bir araya gelmeninine minimuma ulaşmanın daha uzun süreceği anlamına gelir.\n","Verileri μ = 0 ve σ = 1 olacak şekilde ölçeklendirebilirsiniz. Her örneği ölçeklendirme formülü aşağıdadır:\n","\n","Her itersyonda, her bir parametre için **J (w) w.r.t** maliyet fonksiyonunun kısmi türevini alın.\n","\n","![Denkemler](https://i.hizliresim.com/GmXXa6.png)\n","\n","İllüstrasyonda, bias olmadığını varsayalım. Eğer mevcut değerin w> 0 eğimi ise, bu, optimal w* nin sağında olduğumuz anlamına gelir. Bu nedenle, güncelleme negatif olacak ve w* 'nin optimum değerlerine yaklaşmaya başlayacaktır. Bununla birlikte, negatifse, güncelleme pozitif olacaktır ve w* 'nin optimum değerlerine yakınsamak için mevcut w değerini artıracaktır.\n","\n","![](https://imaddabbura.github.io/img/gradient_descent_algorithms/gradients.PNG)\n","\n","\n","\n","---\n","\n","\n","Stokastik gradyan iniş ile klasik gradyan iniş algoritması arasında aşağıdaki görselden anlaşılacağı gibi salınım farkı vardır. Bu osilasyon gerçek minimum değerini yakalamakta yardımcı olurken maalesef stokastik gradyan iniş algritmasının yakınsama hızını oldukça yavaşlatmaktadır. \n","\n","![SGD-GD](https://datascience-enthusiast.com/figures/kiank_sgd.png)\n","\n","Bunun yerine bir ortayol bulunarak mini-kümeli gradyan iniş algoritmasın da uygulanabilir. Böylece az salınım ile hatayı minimize eden değer aranabilir.\n","\n","![SGD-MBGD](https://datascience-enthusiast.com/figures/kiank_minibatch.png)\n","\n","\n","\n","---\n","\n","### En çok kullanılan optimizasyon algoritmalarının minimuma yakınsama hızlarının karşılaştırılması\n","\n","![cs231n](https://cdn-images-1.medium.com/max/800/1*XVFmo9NxLnwDr3SxzKy-rA.gif)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Zl6kT2naQujy"},"source":["### Google Colab Kimlik Doğrulama İşlemi\n","\n","Klasik Colab kimlik doğrulama işlemi ile başlayalım!"]},{"cell_type":"code","metadata":{"id":"tCyIxEY6P3tp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635678574482,"user_tz":-180,"elapsed":25880,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"c7508279-aa19-407f-8773-bdf4a84fa0b4"},"source":["from google.colab import drive\n","drive.mount('/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive/\n"]}]},{"cell_type":"markdown","metadata":{"id":"82C-ngQ0RSuW"},"source":["### Kütüphanelerin kurulması ve gerekli importların yapılması adımı\n","⏬⏬⏬"]},{"cell_type":"code","metadata":{"id":"VEzr1ibOQ4S4"},"source":["!pip install -q keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JDCBn987Q8Eq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635678587616,"user_tz":-180,"elapsed":1904,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"bfb8a3cc-db88-495a-9594-09e1ba2a141b"},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import load_model\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras. layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","import tensorflow  as tf\n","from keras.layers import *\n","from keras.callbacks import ReduceLROnPlateau\n","from tensorflow.python.keras import regularizers\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"markdown","metadata":{"id":"j8M4qym0RbPN"},"source":["## Veri Setinin İndirilmesi\n"," 0️⃣ 1️⃣ 2️⃣ 3️⃣ 4️⃣ 5️⃣ 6️⃣ 7️⃣ 8️⃣ 9️⃣ "]},{"cell_type":"code","metadata":{"id":"A8Ft_MHjQ_td","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635678591491,"user_tz":-180,"elapsed":1108,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"33903fc3-43db-4d97-89b7-30977a4b4824"},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"NHb18AfaR54m"},"source":["### Yapılandırma Ayarları\n","Küme boyutu, sınıf sayısı, eğitim epoch sayısı gibi parametreleri tüm optimizasyon denemeleri için aynı şekilde ayarlıyoruz!"]},{"cell_type":"code","metadata":{"id":"PmdC7R1bs_yG"},"source":["batch_size = 128 # Küme Boyutu\n","num_classes = 10 # Sınıf Sayısı\n","epochs = 20 # Eğitimin epoch sayısı\n","w_l2 = 1e-5 # Başlangıç"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFV8wtBStCRR"},"source":["reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqKMPk4YtfTD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635678596020,"user_tz":-180,"elapsed":245,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"9651e1e6-2641-4dbf-fc9c-6a361b3bc3e5"},"source":["img_rows, img_cols = 28, 28\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# sınıf vektörlerini ikili sınıf matrislerine dönüştürmek\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"]}]},{"cell_type":"code","metadata":{"id":"Yyv7agjBiaLr"},"source":["from keras import optimizers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yoz7Bmu1ZVZ5"},"source":["### Tüm optimizasyon yöntemlerini eğiteceğimiz evrişimli sinir ağı modelinin oluşturulması"]},{"cell_type":"code","metadata":{"id":"pXcn3PNrZUgB"},"source":["model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),  kernel_regularizer=regularizers.l2(w_l2),\n","                 input_shape=input_shape))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3),  kernel_regularizer=regularizers.l2(w_l2)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, kernel_regularizer=regularizers.l2(w_l2)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yplz3Z1PUkL7"},"source":["### STOKASTİK GRADYAN/BAYIR İNİŞ OPTİMİZASYONU\n","\n","Tüm örneklerden geçmek yerine, Stokastik Degrade İniş (SGD), her bir örnekte $(x ^ i, y ^ i)$  parametrelerin güncellenmesini gerçekleştirir. Bu nedenle, öğrenme her örnekte gerçekleşir:\n","\n","$w = w− α∇wJ(x^i,y^i;w,b)$\n","\n","```\n","for i in range(num_epochs):\n","    np.random.shuffle(data)\n","    for example in data:\n","        grad = compute_gradient(example, params)\n","        params = params - learning_rate * grad\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"F3Ehq8baUiNQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635678610754,"user_tz":-180,"elapsed":226,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"7f897a0c-b9a3-43c1-a351-9021448863f8"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.SGD(),\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,200,778\n","Trainable params: 1,200,330\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"7GgoYOCxyvSA"},"source":["### Modelin Eğitilm ve Test Sonuçları "]},{"cell_type":"code","metadata":{"id":"so9wTRPPUtIf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635678926985,"user_tz":-180,"elapsed":314717,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"cd615f36-3881-4260-e8fb-3867d19da87a"},"source":["hist_SGD=model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test), callbacks=[reduce_lr])\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 21s 354us/step - loss: 0.4734 - accuracy: 0.8676 - val_loss: 0.5759 - val_accuracy: 0.8348\n","Epoch 2/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.2195 - accuracy: 0.9441 - val_loss: 0.1023 - val_accuracy: 0.9748\n","Epoch 3/20\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.1698 - accuracy: 0.9563 - val_loss: 0.0803 - val_accuracy: 0.9799\n","Epoch 4/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.1429 - accuracy: 0.9631 - val_loss: 0.0697 - val_accuracy: 0.9816\n","Epoch 5/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.1290 - accuracy: 0.9666 - val_loss: 0.0648 - val_accuracy: 0.9839\n","Epoch 6/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.1158 - accuracy: 0.9701 - val_loss: 0.0590 - val_accuracy: 0.9844\n","Epoch 7/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.1089 - accuracy: 0.9713 - val_loss: 0.0537 - val_accuracy: 0.9854\n","Epoch 8/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.1021 - accuracy: 0.9735 - val_loss: 0.0526 - val_accuracy: 0.9858\n","Epoch 9/20\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0937 - accuracy: 0.9752 - val_loss: 0.0507 - val_accuracy: 0.9860\n","Epoch 10/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.0894 - accuracy: 0.9766 - val_loss: 0.0486 - val_accuracy: 0.9866\n","Epoch 11/20\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0850 - accuracy: 0.9775 - val_loss: 0.0450 - val_accuracy: 0.9876\n","Epoch 12/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0823 - accuracy: 0.9778 - val_loss: 0.0444 - val_accuracy: 0.9880\n","Epoch 13/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0797 - accuracy: 0.9785 - val_loss: 0.0419 - val_accuracy: 0.9881\n","Epoch 14/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0750 - accuracy: 0.9801 - val_loss: 0.0404 - val_accuracy: 0.9889\n","Epoch 15/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0393 - val_accuracy: 0.9887\n","Epoch 16/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.0715 - accuracy: 0.9799 - val_loss: 0.0388 - val_accuracy: 0.9888\n","Epoch 17/20\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0694 - accuracy: 0.9814 - val_loss: 0.0389 - val_accuracy: 0.9883\n","Epoch 18/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0663 - accuracy: 0.9823 - val_loss: 0.0379 - val_accuracy: 0.9890\n","Epoch 19/20\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0655 - accuracy: 0.9824 - val_loss: 0.0372 - val_accuracy: 0.9896\n","Epoch 20/20\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.0640 - accuracy: 0.9823 - val_loss: 0.0364 - val_accuracy: 0.9896\n","Test loss: 0.0364313871905\n","Test accuracy: 0.989600002766\n"]}]},{"cell_type":"markdown","metadata":{"id":"KYolqTuQT9W0"},"source":["### ADAM OPTİMİZASYONU\n","***Adam veya adaptif momentum AdaDelta’ya benzer bir algoritmadır. AdaDelta’dan farklı olarak parametrelerin her birinin öğrenme oranlarının yanısıra momentum değişikliklerini de önbellekte (cache) saklar; yani RMSprop ve momentumu birleştirir.***"]},{"cell_type":"code","metadata":{"id":"n0EE587KUBqg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635679871189,"user_tz":-180,"elapsed":219,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"0c1830c0-56f5-4cb5-e02a-947a20067479"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adam(),\n","              metrics=['accuracy'])\n","\n","\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,200,778\n","Trainable params: 1,200,330\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"0yql0c0Cyh0F"},"source":["### Modelin Eğitilm ve Test Sonuçları \n"]},{"cell_type":"code","metadata":{"id":"PfvkKy_NUd1J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635680215914,"user_tz":-180,"elapsed":342488,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"6cfa7dc8-b691-47ba-ab77-96bd27dc1678"},"source":["hist_ADAM=model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test), callbacks=[reduce_lr])\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 18s 301us/step - loss: 0.1010 - accuracy: 0.9712 - val_loss: 0.0552 - val_accuracy: 0.9842\n","Epoch 2/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0690 - accuracy: 0.9815 - val_loss: 0.0450 - val_accuracy: 0.9873\n","Epoch 3/20\n","60000/60000 [==============================] - 17s 282us/step - loss: 0.0591 - accuracy: 0.9848 - val_loss: 0.0499 - val_accuracy: 0.9875\n","Epoch 4/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0552 - accuracy: 0.9863 - val_loss: 0.0447 - val_accuracy: 0.9893\n","Epoch 5/20\n","60000/60000 [==============================] - 17s 282us/step - loss: 0.0504 - accuracy: 0.9882 - val_loss: 0.0387 - val_accuracy: 0.9918\n","Epoch 6/20\n","60000/60000 [==============================] - 17s 282us/step - loss: 0.0487 - accuracy: 0.9887 - val_loss: 0.0485 - val_accuracy: 0.9892\n","Epoch 7/20\n","60000/60000 [==============================] - 17s 282us/step - loss: 0.0480 - accuracy: 0.9899 - val_loss: 0.0456 - val_accuracy: 0.9912\n","Epoch 8/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0467 - accuracy: 0.9908 - val_loss: 0.0412 - val_accuracy: 0.9928\n","Epoch 9/20\n","60000/60000 [==============================] - 17s 280us/step - loss: 0.0464 - accuracy: 0.9913 - val_loss: 0.0452 - val_accuracy: 0.9915\n","Epoch 10/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0442 - accuracy: 0.9923 - val_loss: 0.0457 - val_accuracy: 0.9925\n","Epoch 11/20\n","60000/60000 [==============================] - 17s 280us/step - loss: 0.0373 - accuracy: 0.9949 - val_loss: 0.0415 - val_accuracy: 0.9934\n","Epoch 12/20\n","60000/60000 [==============================] - 17s 282us/step - loss: 0.0347 - accuracy: 0.9956 - val_loss: 0.0399 - val_accuracy: 0.9936\n","Epoch 13/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0304 - accuracy: 0.9968 - val_loss: 0.0406 - val_accuracy: 0.9932\n","Epoch 14/20\n","60000/60000 [==============================] - 17s 283us/step - loss: 0.0306 - accuracy: 0.9969 - val_loss: 0.0407 - val_accuracy: 0.9932\n","Epoch 15/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0283 - accuracy: 0.9971 - val_loss: 0.0389 - val_accuracy: 0.9935\n","Epoch 16/20\n","60000/60000 [==============================] - 17s 283us/step - loss: 0.0269 - accuracy: 0.9975 - val_loss: 0.0388 - val_accuracy: 0.9936\n","Epoch 17/20\n","60000/60000 [==============================] - 17s 282us/step - loss: 0.0265 - accuracy: 0.9978 - val_loss: 0.0384 - val_accuracy: 0.9936\n","Epoch 18/20\n","60000/60000 [==============================] - 17s 283us/step - loss: 0.0259 - accuracy: 0.9979 - val_loss: 0.0380 - val_accuracy: 0.9938\n","Epoch 19/20\n","60000/60000 [==============================] - 17s 281us/step - loss: 0.0256 - accuracy: 0.9977 - val_loss: 0.0379 - val_accuracy: 0.9937\n","Epoch 20/20\n","60000/60000 [==============================] - 17s 279us/step - loss: 0.0253 - accuracy: 0.9981 - val_loss: 0.0381 - val_accuracy: 0.9937\n","Test loss: 0.0381288529724\n","Test accuracy: 0.993700027466\n"]}]},{"cell_type":"markdown","metadata":{"id":"dEyzCokVUvSV"},"source":["### RMSprop OPTİMİZASYONU\n","\n","***RMSprop ve benzeri olan AdaDelta, AdaGrad’ın bu sorununu çözerek bu hızlı düşüşü önler.***"]},{"cell_type":"code","metadata":{"id":"Gd5HV0OsCtTz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635680232485,"user_tz":-180,"elapsed":223,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"d7f1babb-f0cc-41ea-aa11-18581d151df0"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.RMSprop(),\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,200,778\n","Trainable params: 1,200,330\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"9FKUYBcqFQ55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635680568912,"user_tz":-180,"elapsed":334034,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"03bf7dea-36bd-45a5-f616-ad553e4f0bb0"},"source":["hist_RMSprob=model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test), callbacks=[reduce_lr])\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 17s 290us/step - loss: 0.0339 - accuracy: 0.9943 - val_loss: 0.0557 - val_accuracy: 0.9917\n","Epoch 2/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0380 - accuracy: 0.9932 - val_loss: 0.0550 - val_accuracy: 0.9920\n","Epoch 3/20\n","60000/60000 [==============================] - 16s 275us/step - loss: 0.0385 - accuracy: 0.9932 - val_loss: 0.0759 - val_accuracy: 0.9864\n","Epoch 4/20\n","60000/60000 [==============================] - 17s 275us/step - loss: 0.0417 - accuracy: 0.9928 - val_loss: 0.0629 - val_accuracy: 0.9908\n","Epoch 5/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0448 - accuracy: 0.9923 - val_loss: 0.0801 - val_accuracy: 0.9882\n","Epoch 6/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0475 - accuracy: 0.9923 - val_loss: 0.0595 - val_accuracy: 0.9923\n","Epoch 7/20\n","60000/60000 [==============================] - 16s 273us/step - loss: 0.0474 - accuracy: 0.9923 - val_loss: 0.0668 - val_accuracy: 0.9911\n","Epoch 8/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0412 - accuracy: 0.9946 - val_loss: 0.0548 - val_accuracy: 0.9922\n","Epoch 9/20\n","60000/60000 [==============================] - 17s 275us/step - loss: 0.0370 - accuracy: 0.9959 - val_loss: 0.0496 - val_accuracy: 0.9926\n","Epoch 10/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0342 - accuracy: 0.9963 - val_loss: 0.0499 - val_accuracy: 0.9936\n","Epoch 11/20\n","60000/60000 [==============================] - 17s 275us/step - loss: 0.0336 - accuracy: 0.9962 - val_loss: 0.0480 - val_accuracy: 0.9933\n","Epoch 12/20\n","60000/60000 [==============================] - 17s 276us/step - loss: 0.0323 - accuracy: 0.9967 - val_loss: 0.0522 - val_accuracy: 0.9934\n","Epoch 13/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0328 - accuracy: 0.9964 - val_loss: 0.0535 - val_accuracy: 0.9932\n","Epoch 14/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0313 - accuracy: 0.9967 - val_loss: 0.0463 - val_accuracy: 0.9934\n","Epoch 15/20\n","60000/60000 [==============================] - 16s 273us/step - loss: 0.0304 - accuracy: 0.9965 - val_loss: 0.0483 - val_accuracy: 0.9932\n","Epoch 16/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0292 - accuracy: 0.9972 - val_loss: 0.0508 - val_accuracy: 0.9933\n","Epoch 17/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0287 - accuracy: 0.9973 - val_loss: 0.0448 - val_accuracy: 0.9939\n","Epoch 18/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0274 - accuracy: 0.9973 - val_loss: 0.0505 - val_accuracy: 0.9938\n","Epoch 19/20\n","60000/60000 [==============================] - 16s 274us/step - loss: 0.0283 - accuracy: 0.9971 - val_loss: 0.0471 - val_accuracy: 0.9938\n","Epoch 20/20\n","60000/60000 [==============================] - 17s 276us/step - loss: 0.0278 - accuracy: 0.9970 - val_loss: 0.0451 - val_accuracy: 0.9938\n","Test loss: 0.0450622974694\n","Test accuracy: 0.993799984455\n"]}]},{"cell_type":"markdown","metadata":{"id":"9V_WJzZFAi2S"},"source":["### ADAGRAD OPTİMİZASYONU\n","\n","***AdaGrad seyrek parametreler için büyük güncellemeler yaparken sık parametreler için daha küçük güncellemeler yapar. Bu nedenle NLP ve resim tanıma gibi seyrek veriler için daha uygundur.***\n","AdaGrad’da her parametrenin kendi öğrenme hızı vardır ve algoritmanın özelliklerine bağlı olarak öğrenme oranı giderek azalmaktadır. Bu nedenle öğreneme oranı giderek azalır ve zamanın bir noktasında sistem öğrenmeyi bırakır. Bu AdaGrad’ın en büyük dez avantajıdır."]},{"cell_type":"code","metadata":{"id":"otVDerwEC3d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635680972165,"user_tz":-180,"elapsed":3,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"66499e2b-43b2-40b6-86aa-0a094b306dde"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adagrad(),\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,200,778\n","Trainable params: 1,200,330\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"PxMf0Mv7GRQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635681302976,"user_tz":-180,"elapsed":329788,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"18ce829b-9c3c-4c2e-8d22-9ad2ae675a83"},"source":["hist_adagrad=model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test), callbacks=[reduce_lr])\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 17s 284us/step - loss: 0.0603 - accuracy: 0.9884 - val_loss: 0.0455 - val_accuracy: 0.9926\n","Epoch 2/20\n","60000/60000 [==============================] - 16s 270us/step - loss: 0.0373 - accuracy: 0.9944 - val_loss: 0.0442 - val_accuracy: 0.9927\n","Epoch 3/20\n","60000/60000 [==============================] - 16s 270us/step - loss: 0.0328 - accuracy: 0.9958 - val_loss: 0.0464 - val_accuracy: 0.9933\n","Epoch 4/20\n","60000/60000 [==============================] - 16s 270us/step - loss: 0.0308 - accuracy: 0.9962 - val_loss: 0.0421 - val_accuracy: 0.9930\n","Epoch 5/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0301 - accuracy: 0.9966 - val_loss: 0.0486 - val_accuracy: 0.9931\n","Epoch 6/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0286 - accuracy: 0.9969 - val_loss: 0.0457 - val_accuracy: 0.9929\n","Epoch 7/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0283 - accuracy: 0.9970 - val_loss: 0.0430 - val_accuracy: 0.9937\n","Epoch 8/20\n","60000/60000 [==============================] - 16s 273us/step - loss: 0.0275 - accuracy: 0.9973 - val_loss: 0.0456 - val_accuracy: 0.9929\n","Epoch 9/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0267 - accuracy: 0.9974 - val_loss: 0.0424 - val_accuracy: 0.9935\n","Epoch 10/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0253 - accuracy: 0.9978 - val_loss: 0.0423 - val_accuracy: 0.9935\n","Epoch 11/20\n","60000/60000 [==============================] - 16s 272us/step - loss: 0.0253 - accuracy: 0.9979 - val_loss: 0.0422 - val_accuracy: 0.9937\n","Epoch 12/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.0417 - val_accuracy: 0.9934\n","Epoch 13/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0245 - accuracy: 0.9982 - val_loss: 0.0423 - val_accuracy: 0.9934\n","Epoch 14/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0245 - accuracy: 0.9980 - val_loss: 0.0417 - val_accuracy: 0.9933\n","Epoch 15/20\n","60000/60000 [==============================] - 16s 270us/step - loss: 0.0252 - accuracy: 0.9977 - val_loss: 0.0425 - val_accuracy: 0.9934\n","Epoch 16/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0252 - accuracy: 0.9979 - val_loss: 0.0419 - val_accuracy: 0.9933\n","Epoch 17/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0244 - accuracy: 0.9982 - val_loss: 0.0416 - val_accuracy: 0.9934\n","Epoch 18/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0244 - accuracy: 0.9980 - val_loss: 0.0422 - val_accuracy: 0.9933\n","Epoch 19/20\n","60000/60000 [==============================] - 16s 273us/step - loss: 0.0248 - accuracy: 0.9979 - val_loss: 0.0418 - val_accuracy: 0.9935\n","Epoch 20/20\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.0234 - accuracy: 0.9984 - val_loss: 0.0423 - val_accuracy: 0.9934\n","Test loss: 0.0423050601751\n","Test accuracy: 0.993399977684\n"]}]},{"cell_type":"markdown","metadata":{"id":"-SjWtxBJAo1F"},"source":["### ADADELTA OPTİMİZASYONU\n","***AdaDelta, AdaGrad’ın bu sorununu çözerek bu hızlı düşüşü önler.***"]},{"cell_type":"code","metadata":{"id":"K8ZC_xhVDB-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635681463922,"user_tz":-180,"elapsed":245,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"532eed84-e75d-417b-e40d-8a07a54908be"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,200,778\n","Trainable params: 1,200,330\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"N9YEflZYGWwU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635681815352,"user_tz":-180,"elapsed":350393,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"2f6899f3-78c3-4180-8a59-1875c3f596f4"},"source":["hist_adadelta=model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test), callbacks=[reduce_lr])\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 18s 306us/step - loss: 0.0277 - accuracy: 0.9969 - val_loss: 0.0546 - val_accuracy: 0.9930\n","Epoch 2/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0273 - accuracy: 0.9972 - val_loss: 0.0442 - val_accuracy: 0.9937\n","Epoch 3/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0266 - accuracy: 0.9973 - val_loss: 0.0459 - val_accuracy: 0.9932\n","Epoch 4/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0268 - accuracy: 0.9972 - val_loss: 0.0492 - val_accuracy: 0.9938\n","Epoch 5/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0257 - accuracy: 0.9976 - val_loss: 0.0407 - val_accuracy: 0.9929\n","Epoch 6/20\n","60000/60000 [==============================] - 17s 289us/step - loss: 0.0259 - accuracy: 0.9973 - val_loss: 0.0492 - val_accuracy: 0.9933\n","Epoch 7/20\n","60000/60000 [==============================] - 17s 288us/step - loss: 0.0247 - accuracy: 0.9978 - val_loss: 0.0441 - val_accuracy: 0.9931\n","Epoch 8/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0249 - accuracy: 0.9979 - val_loss: 0.0464 - val_accuracy: 0.9917\n","Epoch 9/20\n","60000/60000 [==============================] - 17s 286us/step - loss: 0.0264 - accuracy: 0.9972 - val_loss: 0.0422 - val_accuracy: 0.9939\n","Epoch 10/20\n","60000/60000 [==============================] - 17s 288us/step - loss: 0.0259 - accuracy: 0.9974 - val_loss: 0.0473 - val_accuracy: 0.9936\n","Epoch 11/20\n","60000/60000 [==============================] - 17s 288us/step - loss: 0.0231 - accuracy: 0.9982 - val_loss: 0.0433 - val_accuracy: 0.9934\n","Epoch 12/20\n","60000/60000 [==============================] - 17s 289us/step - loss: 0.0228 - accuracy: 0.9984 - val_loss: 0.0457 - val_accuracy: 0.9937\n","Epoch 13/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0229 - accuracy: 0.9983 - val_loss: 0.0448 - val_accuracy: 0.9936\n","Epoch 14/20\n","60000/60000 [==============================] - 17s 288us/step - loss: 0.0224 - accuracy: 0.9984 - val_loss: 0.0446 - val_accuracy: 0.9933\n","Epoch 15/20\n","60000/60000 [==============================] - 17s 289us/step - loss: 0.0226 - accuracy: 0.9984 - val_loss: 0.0432 - val_accuracy: 0.9935\n","Epoch 16/20\n","60000/60000 [==============================] - 17s 289us/step - loss: 0.0217 - accuracy: 0.9985 - val_loss: 0.0440 - val_accuracy: 0.9936\n","Epoch 17/20\n","60000/60000 [==============================] - 17s 290us/step - loss: 0.0217 - accuracy: 0.9987 - val_loss: 0.0447 - val_accuracy: 0.9937\n","Epoch 18/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0218 - accuracy: 0.9986 - val_loss: 0.0446 - val_accuracy: 0.9937\n","Epoch 19/20\n","60000/60000 [==============================] - 17s 289us/step - loss: 0.0216 - accuracy: 0.9987 - val_loss: 0.0433 - val_accuracy: 0.9938\n","Epoch 20/20\n","60000/60000 [==============================] - 17s 287us/step - loss: 0.0214 - accuracy: 0.9987 - val_loss: 0.0435 - val_accuracy: 0.9936\n","Test loss: 0.0434971768767\n","Test accuracy: 0.993600010872\n"]}]},{"cell_type":"markdown","metadata":{"id":"XUTx9aZ5y8-A"},"source":["## Kaydedilen sonuçların çizilmesi için plot fonksiyonunun tanımlanması"]},{"cell_type":"code","metadata":{"id":"ZSit3Yplyu8N"},"source":["def plot_history(hists, attribute='val_loss', axis=(-1,21,0.85,0.94), loc='lower right'):\n","    ylabel = {'oss': 'loss', 'acc': 'acc'}\n","    title = {'val_loss': 'valid. loss', 'loss': 'trn. loss', 'val_acc': 'valid. accuracy', 'acc': 'trn. accuracy'}\n","    num_hists = len(hists)\n","    \n","    plt.figure(figsize=(12, 8))  \n","    plt.axis(axis)\n","    for i in range(num_hists):\n","        plt.plot(hists[i].history[attribute])\n","    plt.title(title[attribute])  \n","    plt.ylabel(ylabel[attribute[-3:]])  \n","    plt.xlabel('epoch')  \n","    plt.legend(['ADAM', 'SGD', 'RMSprob', 'adadelta', 'adagrad'], loc=loc)  \n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKMJEGdnyxRx"},"source":["hists = [hist_ADAM, hist_SGD, hist_RMSprob, hist_adadelta, hist_adagrad]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NXV_DNLIz6qh"},"source":["## SONUÇLARIN KARŞILAŞTIRILMASI"]},{"cell_type":"code","metadata":{"id":"A-DMymV4z5nf"},"source":["plot_history(hists, attribute='accuracy', axis=(-0.1,20,0.85,1), loc='lower right')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IH1fj_610Egs","colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"status":"ok","timestamp":1635683171720,"user_tz":-180,"elapsed":676,"user":{"displayName":"ayyüce kızrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk6iMtpvKiCAN5you3Kz0gUPzeKCQ5qaCfCAHw4g=s64","userId":"06068240104523019363"}},"outputId":"07f4f132-1829-4542-af52-176807b229a0"},"source":["plot_history(hists, attribute='loss', axis=(-0.5,20,0.0009,0.5), loc='upper right')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"6bO_9_u5XOsm"},"source":["# SONUÇ\n","Kullandığımız optimizasyon algoritmasına göre epoch süresince eğitim hatasının nasıl değiştiğini çizdirdiğimiz grafiklerden inceleyebiliyoruz. Hatta öyle ki örneğin derin öğrenme modellerindençok sık kullanılan Stokastik Gradyan/Bayır İniş algoritması için değişmeyen diğer tüm parametreler durumunda bu problem için **20 Epoch** tan daha önce de eğitimi sonlandırabiliriz. \n","\n","![Happy Dance](https://gfx-bloggar.aftonbladet-cdn.se/wp-content/blogs.dir/428/files/2017/07/tenor-21.gif) \n","\n","*Burn After Reading Filminden :)*\n","\n","\n","### Test Yitim Değerlerini de aşağıdaki tablo ile inceleyeyim:\n","\n","\n","![TEST SONUÇLARI](https://i.hizliresim.com/alRa2B.png)\n","\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fXv6BFXzW7zs"},"source":["## KAYNAKLAR\n","---\n","* [Kaynak 1]( http://sebastianruder.com/optimizing-gradient-descent/) Optimizing Gradient Descent-Dean, J., Corrado, G. S., Monga, R., Chen, K., Devin, M., Le, Q. V, … Ng, A. Y. (2012). Large Scale Distributed Deep Networks. NIPS 2012: Neural Information Processing Systems.\n","\n","* [Kaynak 2](http://proceedings.mlr.press/v37/ioffe15.pdf) Ioffe, S., & Szegedy, C. (2015). Batch Normalization : Accelerating Deep Network Training by Reducing Internal Covariate Shift. arXiv Preprint arXiv:1502.03167v3.\n","\n","* [Kaynak 3](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.5612&rep=rep1&type=pdf) Qian, N. (1999). On the momentum term in gradient descent learning algorithms. Neural Networks : The Official Journal of the International Neural Network Society, 12(1), 145–151.\n","\n","* [Kaynak 4](https://arxiv.org/pdf/1412.6980.pdf) Kingma, D. P., & Ba, J. L. (2015). Adam: a Method for Stochastic Optimization. International Conference on Learning Representations\n","Zaremba, W., & Sutskever, I. (2014). Learning to Execute, 1–25.\n","\n","* [Kaynak 5](https://arxiv.org/pdf/1412.6651.pdf) Zhang, S., Choromanska, A., & LeCun, Y. (2015). Deep learning with Elastic Averaging SGD. Neural Information Processing Systems Conference (NIPS 2015).\n","\n","* [Kaynak 6](https://ieeexplore.ieee.org/document/253713) Darken, C., Chang, J., & Moody, J. (1992). Learning rate schedules for faster stochastic gradient search. Neural Networks for Signal Processing II Proceedings of the 1992 IEEE Workshop, (September). \n","\n","* [Kaynak 7](https://keras.io/optimizers/) Usage of optimizers, Keras Docs\n","\n","* [Kaynak 8](https://www.coursera.org/specializations/deep-learning) Coursera- deeplearning.ai, Deep Learning Specialization\n","\n","* [Kaynak 9](https://imaddabbura.github.io/post/gradient_descent_algorithms/) Gradient Descent Algorithm and Its Variants\n","\n","* [Kaynak 10](https://medium.com/@jrodthoughts/improving-deep-learning-algorithms-optimization-vs-regularization-f9b6e86fee8c) Improving Deep Learning Algorithms: Optimization vs. Regularization\n","\n","* [Kaynak 11](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f) Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent\n","\n","* [Kaynak 12](http://cs231n.github.io/optimization-1/) CS231n - Convolutional Neural Networks for Visual Recognition\n","\n","* [Kaynak 13](https://medium.com/deep-learning-turkiye/derin-ogrenme-uygulamalarinda-en-sik-kullanilan-hiper-parametreler-ece8e9125c4) Derin Öğrenme Uygulamalarında En Sık kullanılan Hiper-parametreler"]}]}