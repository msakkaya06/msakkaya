{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM__TPU_Egitimi.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"vHqkRXgVqWC7","colab_type":"text"},"cell_type":"markdown","source":["# **Google Colab TPU Kulanarak Shakespeare Kestirimi  (LSTM )**\n","\n","\n","\n","---\n","\n","\n","**Kaynak:** *[Google Colab -Tutorial](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb)*\n","\n","[<img align=\"right\" width=\"100\" height=\"100\" src=\"http://www.i2symbol.com/images/symbols/style-letters/circled_latin_capital_letter_a_u24B6_icon_128x128.png\">](https://www.ayyucekizrak.com/)"]},{"metadata":{"id":"j6kQKxIWsMuR","colab_type":"text"},"cell_type":"markdown","source":["## Veri İndirme\n","\n","*The Complete Works of William Shakespeare* yazı formatında veriyi [Project Gutenberg](https://www.gutenberg.org/) adresinden indirme işlemi. Dosya içinden paragrafları *eğitim seti* için kullanacağız. *Hedef* için paragraflar birer karakterle ifade edilmektedir."]},{"metadata":{"id":"Oy45RKqPvk84","colab_type":"code","outputId":"07e7e4e7-dff3-4713-c60e-9f3251cb9284","colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["!wget --show-progress --continue -O /content/shakespeare.txt http://www.gutenberg.org/files/100/100-0.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-10-24 11:03:37--  http://www.gutenberg.org/files/100/100-0.txt\n","Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n","Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5852404 (5.6M) [text/plain]\n","Saving to: ‘/content/shakespeare.txt’\n","\n","/content/shakespear 100%[===================>]   5.58M  5.54MB/s    in 1.0s    \n","\n","2018-10-24 11:03:39 (5.54 MB/s) - ‘/content/shakespeare.txt’ saved [5852404/5852404]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"i_Ml311avrqS","colab_type":"text"},"cell_type":"markdown","source":["### Veri Üretici Oluşturma"]},{"metadata":{"id":"yHVJ419BvuuY","colab_type":"code","outputId":"52f3cf5d-08de-4ef3-ad47-1e98b48f9cd1","colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["import numpy as np\n","import six\n","import tensorflow as tf\n","import time\n","import os\n","\n","# Bu adres, TensorFlow'u yapılandırırken kullanacağımız TPU'yu tanımlar.\n","TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","\n","SHAKESPEARE_TXT = '/content/shakespeare.txt'\n","\n","tf.logging.set_verbosity(tf.logging.INFO)\n","\n","def transform(txt, pad_to=None):\n","  # ascii olmayan karakterleri bırakır\n","  output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n","  if pad_to is not None:\n","    output = output[:pad_to]\n","    output = np.concatenate([\n","        np.zeros([pad_to - len(txt)], dtype=np.int32),\n","        output,\n","    ])\n","  return output\n","\n","def training_generator(seq_len=100, batch_size=1024):\n","  \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n","  with tf.gfile.GFile(SHAKESPEARE_TXT, 'r') as f:\n","    txt = f.read()\n","\n","  tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n","  source = transform(txt)\n","  while True:\n","    offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n","\n","    # Modelimiz seyrek çapraz entropi kaybı kullanmaktadır, \n","    # ancak Keras, etiketlerin giriş kayıtlarıyla aynı sıraya sahip olmasını gerektirir. \n","    # Bunu açıklamak için boş bir son boyut ekliyoruz.\n","    \n","    yield (\n","        np.stack([source[idx:idx + seq_len] for idx in offsets]),\n","        np.expand_dims(\n","            np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]),\n","            -1),\n","    )\n","\n","six.next(training_generator(seq_len=10, batch_size=1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Input text [5834393] ﻿\r\n","Project Gutenberg’s The Complete Works of Willi\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(array([[110, 100,  32, 100, 105, 101,  33,  13,  10,  32]], dtype=int32),\n"," array([[[100],\n","         [ 32],\n","         [100],\n","         [105],\n","         [101],\n","         [ 33],\n","         [ 13],\n","         [ 10],\n","         [ 32],\n","         [ 32]]], dtype=int32))"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"zTGf5SurwUzQ","colab_type":"text"},"cell_type":"markdown","source":["## Model Oluşturma\n","\n","Model, iki katmanlı, ileri-LSTM olarak tanımlanmıştır - tf.keras standart LSTM tanımından iki değişiklikle:\n","\n","1. Modelimizin [XLA compiler](https://www.tensorflow.org/performance/xla/) derleyicisinin statik şekil gereksinimini karşılayan giriş `shape`ini tanımlayın..\n","2. Keras optimizer yerine `tf.train.Optimizer` kullanın.(Keras optimizer desteği hala deneysel)."]},{"metadata":{"id":"KMkzDv24zJZ_","colab_type":"code","colab":{}},"cell_type":"code","source":["EMBEDDING_DIM = 512\n","\n","def lstm_model(seq_len=100, batch_size=None, stateful=True):\n","  \"\"\"Language model: predict the next word given the current word.\"\"\"\n","  source = tf.keras.Input(\n","      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n","\n","  embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n","  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n","  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n","  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n","  model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n","  model.compile(\n","      optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n","      loss='sparse_categorical_crossentropy',\n","      metrics=['sparse_categorical_accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YTeps55dzYYQ","colab_type":"text"},"cell_type":"markdown","source":["## Model Eğitimi\n","\n","`tf.keras` fonksiyonu bu aşamada TPU kullanımının sağlanması için `tf.contrib.tpu.keras_to_tpu_model` şeklinde güncellenmesi gerekiyor.\n","Ardından Keras'ta standart eğitim işleminde olduğu gibi `fit`, `predict`, ve `evaluate` kullanılıyor."]},{"metadata":{"id":"CDuTalNpz78A","colab_type":"code","outputId":"85acdf01-bb38-4e59-c274-e11a9b470c85","colab":{"base_uri":"https://localhost:8080/","height":836}},"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","training_model = lstm_model(seq_len=100, batch_size=128, stateful=False)\n","\n","tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n","    training_model,\n","    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n","        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n","\n","tpu_model.fit_generator(\n","    training_generator(seq_len=100, batch_size=1024),\n","    steps_per_epoch=100,\n","    epochs=10,\n",")\n","tpu_model.save_weights('/tmp/bard.h5', overwrite=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Querying Tensorflow master (b'grpc://10.16.57.82:8470') for TPU system metadata.\n","INFO:tensorflow:Found TPU system:\n","INFO:tensorflow:*** Num TPU Cores: 8\n","INFO:tensorflow:*** Num TPU Workers: 1\n","INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8967059024566676383)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4606660762033467324)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 11217221221209779883)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3917334524445245232)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4692620694230546906)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1196013669993184420)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16822105755378850714)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17941462342207817310)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5437015600596746783)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8955965080893340839)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1302688971523713765)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9142998477948371660)\n","WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n","Epoch 1/10\n","INFO:tensorflow:Input text [5834393] ﻿\n","Project Gutenberg’s The Complete Works of Willi\n","INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 100), dtype=tf.int32, name='seed_10'), TensorSpec(shape=(128, 100, 1), dtype=tf.float32, name='time_distributed_target_30')]\n","INFO:tensorflow:Overriding default placeholder.\n","INFO:tensorflow:Remapping placeholder for seed\n","INFO:tensorflow:Started compiling\n","INFO:tensorflow:Finished compiling. Time elapsed: 7.4730353355407715 secs\n","INFO:tensorflow:Setting weights on TPU model.\n","100/100 [==============================] - 39s 392ms/step - loss: 4.5224 - sparse_categorical_accuracy: 0.1876\n","Epoch 2/10\n","100/100 [==============================] - 19s 189ms/step - loss: 3.2099 - sparse_categorical_accuracy: 0.2077\n","Epoch 3/10\n","100/100 [==============================] - 19s 190ms/step - loss: 1.9620 - sparse_categorical_accuracy: 0.4328\n","Epoch 4/10\n","100/100 [==============================] - 19s 189ms/step - loss: 1.3834 - sparse_categorical_accuracy: 0.5799\n","Epoch 5/10\n","100/100 [==============================] - 19s 188ms/step - loss: 1.2499 - sparse_categorical_accuracy: 0.6135\n","Epoch 6/10\n","100/100 [==============================] - 19s 189ms/step - loss: 1.1952 - sparse_categorical_accuracy: 0.6278\n","Epoch 7/10\n","100/100 [==============================] - 19s 189ms/step - loss: 1.1637 - sparse_categorical_accuracy: 0.6360\n","Epoch 8/10\n","100/100 [==============================] - 19s 188ms/step - loss: 1.1421 - sparse_categorical_accuracy: 0.6417\n","Epoch 9/10\n","100/100 [==============================] - 19s 189ms/step - loss: 1.1247 - sparse_categorical_accuracy: 0.6465\n","Epoch 10/10\n","100/100 [==============================] - 19s 188ms/step - loss: 1.1120 - sparse_categorical_accuracy: 0.6499\n","INFO:tensorflow:Copying TPU weights to the CPU\n"],"name":"stdout"}]},{"metadata":{"id":"mg9WinvC0Enz","colab_type":"text"},"cell_type":"markdown","source":["## Model Kestirimlerini Hesaplayın\n","\n","Tahminleri yapmak ve kendi Shakespeare-esque eserinizi oluşturmak için eğitimli modeli kullanın.\n","Modeli bir başlangıç (seed sentence) cümlesi ile başlatın, daha sonra 250 karakterden oluşturun.\n","Başlangıç cümlesinden beş tahmin yapacağız."]},{"metadata":{"id":"acfTWYGW0q4g","colab_type":"code","outputId":"25f0fc3b-ae58-4a8c-8aed-4f2e2c0e90cd","colab":{"base_uri":"https://localhost:8080/","height":1003}},"cell_type":"code","source":["BATCH_SIZE = 5\n","PREDICT_LEN = 250\n","\n","# Keras, durum bilgisi olan modeller için toplu boyutun önceden belirlenmesini gerektirir.\n","# Her seferinde bir karakterde besleyeceğimiz ve bir sonraki karakteri tahmin edeceğimiz için \n","# 1'lik bir dizi uzunluğu kullanırız.\n","\n","prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n","prediction_model.load_weights('/tmp/bard.h5')\n","\n","# Modeli ilk string'i kullanarak ekiyoruz. BATCH_SIZE sayısı kadar kopyalıyoruz.\n","\n","seed_txt = 'Looks it not like the king?  Verily, we must go! '\n","seed = transform(seed_txt)\n","seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n","\n","# Öncelikle, modelin durumunu başlatmak için seed çalıştırın. \n","prediction_model.reset_states()\n","for i in range(len(seed_txt) - 1):\n","  prediction_model.predict(seed[:, i:i + 1])\n","\n","# Şİmdi kestirimleri yapmaya başlayabiliriz!\n","predictions = [seed[:, -1:]]\n","for i in range(PREDICT_LEN):\n","  last_word = predictions[-1]\n","  next_probits = prediction_model.predict(last_word)[:, 0, :]\n","  \n","  # Çıkış dağılımından örnekler\n","  next_idx = [\n","      np.random.choice(256, p=next_probits[i])\n","      for i in range(BATCH_SIZE)\n","  ]\n","  predictions.append(np.asarray(next_idx, dtype=np.int32))\n","  \n","\n","for i in range(BATCH_SIZE):\n","  print('PREDICTION %d\\n\\n' % i)\n","  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n","  generated = ''.join([chr(c) for c in p])\n","  print(generated)\n","  print()\n","  assert len(generated) == PREDICT_LEN, 'Generated text too short'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["PREDICTION 0\n","\n","\n"," They gave me\r\n","    one keeper.\r\n","  SHALLOW. Belike a sort, you shall thrift, if I be my liege;\r\n","    She is one soul forswear, or she comes\r\n","    To her both together it is, the heavens\r\n","    Or to the seat; cheer at me,\r\n","    Wherein I shall make my hear\n","\n","PREDICTION 1\n","\n","\n"," In that rude honour,\r\n","    With grievous Greeks here, for eat my arm;\r\n","    For you call herself fire him, loathd our knees\r\n","    In my hopes, fowls read melies here a controving,\r\n","    Have the provision. Make them here. O, let me stay to deliver\r\n","    \n","\n","PREDICTION 2\n","\n","\n"," And Flesh no man\r\n","    Worse this light, we'll drown thy love;\r\n","  But that hath tongue thoughts churl nothing, I\r\n","To Talbot; this is what to rack this gap in Captain;\r\n","Made our torched bachwith, coals (burn\r\n","And make me swear. What, shall we go in?\r\n","\n","\n","PREDICTION 3\n","\n","\n"," he fought\r\n","    me; and therefore let the treasure marks\r\n","    Like a cold and all but my hands.\r\n","    Ere I ceer the gold affectiond holy fair glory\r\n","    That hopes may gain defacd, wh'right was nothing,\r\n","   To punish this trunchest; here more slaves\r\n","\n","PREDICTION 4\n","\n","\n"," Must I see\r\n","And have their men reverence.\r\n","What, Gertre, leave this main,\r\n","As the lim upon them!\r\n","\r\n","WOMAN.\r\n","What, have I speaks tried her, coal.\r\n","\r\n","LEAR.\r\n","For grant may be shrewdred with you then,\r\n","To scart thee that victorious sons,\r\n","To carry succo\n","\n"],"name":"stdout"}]}]}